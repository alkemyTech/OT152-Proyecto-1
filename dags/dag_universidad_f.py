from airflow import DAG
from datetime import timedelta, datetime
from airflow.operators.dummy import DummyOperator


with DAG(
    'Query_Universidad_F',
    description='Realizar consultas sobre Universidad de Moron y Rio Cuarto',
    schedule_interval=timedelta(hours=1), #ejecuciÃ³n cada una hora
    start_date=datetime(2022, 2, 19) #Puse esa fecha porque no fue aclarada en la consigna

) as dag:
    #Queries usando la funciÃ³n read_sql de pandas
    tarea1 = DummyOperator(task_id='Query_F1') #Universidad de MorÃ³n
    tarea2 = DummyOperator(task_id='Query_F2') #Universidad de RÃ­o Cuarto
    tarea3 = DummyOperator(task_id='Processing_data')#Reading and processing data using read_sql
    tarea4 = DummyOperator(task_id='Upload_S3')#uploading data to s3
    [tarea1,tarea2]>> tarea3 >> tarea4